# 动态区块链网络扩展开发文档

## 项目概述

本文档详细描述了如何扩展现有区块链P2P网络，实现对等方的动态加入和离开功能。在基础实现中，区块链网络中的对等方数量是固定的，通过修改本文档中描述的内容，可以支持对等方动态加入或离开系统，而不影响其他对等方的操作。

## 1. 系统架构

### 1.1 总体架构

动态区块链网络基于现有的P2P网络架构，通过以下扩展实现节点的动态管理：

- **节点管理服务**：提供节点创建、删除和监控功能
- **动态配置机制**：实现配置的动态更新和分发
- **增强的节点发现协议**：支持节点动态加入和离开的通知
- **区块链状态同步优化**：加速新节点的初始同步过程

### 1.2 核心组件

1. **动态Docker容器管理**
   - 动态创建和销毁Docker容器
   - 自动IP分配和端口映射

2. **配置管理系统**
   - 动态生成和更新配置
   - 配置分发和同步

3. **增强的节点发现机制**
   - 新节点加入通知
   - 节点离开处理
   - 网络拓扑维护

4. **区块链同步优化**
   - 快速区块同步
   - 增量状态更新

### 1.3 引导节点策略

本实现使用现有config.json中定义的11个节点(5000-5010)作为初始引导节点。新节点加入网络时，会首先连接到这些预定义的引导节点，然后通过它们发现网络中的其他节点。

## 2. 新节点创建和加入过程

### 2.1 新节点创建

#### 2.1.1 动态Docker容器创建和离开

Windows环境下的Docker命令需要特殊处理：

**方法：使用简化的docker-compose命令**
```bash
# Windows环境下创建新节点的简化命令
docker-compose run -d --name peer5011 -p 6011:5011 -p 8011:7011 peer5000 python node.py --id 5011 --config config.json --dynamic
```
```bash
# 停止指定节点容器
docker stop peer5022

# 如果需要完全删除容器
docker rm peer5022
```

#### 2.1.2 初始配置生成
```json
// 动态配置示例 (新节点的config.json)
{
  "peers": {
    // 保留现有11个节点(5000-5010)作为引导节点
    "5000": {
      "ip": "172.28.0.10",
      "port": 5000,
      "fanout": 1,
      "mode": "malicious"
    },
    "5001": {
      "ip": "172.28.0.11",
      "port": 5001,
      "fanout": 1
    },
    // ... 其他现有节点 ...
    "5010": {
      "ip": "172.28.0.20",
      "port": 5010,
      "fanout": 1,
      "nat": true
    },
    // 新节点配置
    "NEW_PEER_ID": {
      "ip": "NEW_PEER_IP",
      "port": NEW_PEER_PORT,
      "fanout": 1
    }
  },
  "dynamic_discovery": true
}
```

### 2.2 网络加入过程

#### 2.2.1 初始通信
扩展现有的`peer_discovery.py`中的HELLO消息处理，使用现有的11个节点作为引导节点：

```python
def start_peer_discovery(self_id, self_info):
    from outbox import enqueue_message
    
    # 使用配置文件中的11个初始节点作为引导节点
    bootstrap_peers = {}
    with open('config.json') as f:
        config = json.load(f)
        for peer_id, peer_info in config["peers"].items():
            if peer_id != self_id:  # 排除自己
                bootstrap_peers[peer_id] = (peer_info["ip"], peer_info["port"])
    
    def loop():
        # 创建HELLO消息
        msg = {
            "type": "HELLO",
            "sender_id": self_id,
            "ip": self_info["ip"],
            "port": self_info["port"],
            "flags": {
                "nat": self_info.get("nat", False),
                "light": self_info.get("light", False),
                "new_node": True  # 标记为新节点
            },
            "message_id": generate_message_id()
        }

        # 向所有引导节点发送HELLO消息
        for peer_id, (peer_ip, peer_port) in bootstrap_peers.items():
            enqueue_message(peer_id, peer_ip, peer_port, msg)
            
        # 等待初始响应
        time.sleep(5)
        
        # 后续定期发送给所有已知节点
        while True:
            msg["flags"]["new_node"] = False  # 不再是新节点
            for peer_id, (peer_ip, peer_port) in known_peers.items():
                enqueue_message(peer_id, peer_ip, peer_port, msg)
            time.sleep(30)

    threading.Thread(target=loop, daemon=True).start()
```

#### 2.2.2 网络广播
实现新的节点通知消息类型：

```python
def handle_hello_message(msg, self_id):
    sender_id = msg.get("sender_id")
    sender_ip = msg.get("ip")
    sender_port = msg.get("port")
    sender_flags = msg.get("flags", {})
    
    # 检查是否是新节点
    is_new_node = sender_flags.get("new_node", False)

    # 不处理自己的HELLO
    if sender_id == self_id:
        return []

    new_peers = []
    
    # 添加到已知节点表
    if sender_id not in known_peers:
        known_peers[sender_id] = (sender_ip, sender_port)
        new_peers.append(sender_id)
        
        # 如果是新节点，向其他所有节点广播NEW_PEER消息
        if is_new_node:
            broadcast_new_peer(sender_id, sender_ip, sender_port, sender_flags)
    
    # 无论节点是否已知，都更新flags信息
    peer_flags[sender_id] = {
        "nat": sender_flags.get("nat", False),
        "light": sender_flags.get("light", False)
    }

    # 可达性更新
    if sender_id not in reachable_by:
        reachable_by[sender_id] = set()

    reachable_by[sender_id].add(self_id)

    return new_peers

def broadcast_new_peer(new_peer_id, new_peer_ip, new_peer_port, new_peer_flags):
    """向所有已知节点广播新节点信息"""
    from outbox import enqueue_message
    
    msg = {
        "type": "NEW_PEER",
        "new_peer_id": new_peer_id,
        "new_peer_ip": new_peer_ip,
        "new_peer_port": new_peer_port,
        "new_peer_flags": new_peer_flags,
        "message_id": generate_message_id()
    }
    
    for peer_id, (peer_ip, peer_port) in known_peers.items():
        if peer_id != new_peer_id:  # 不发送给新节点自己
            enqueue_message(peer_id, peer_ip, peer_port, msg)
```

## 3. 信息交换与同步过程

### 3.1 网络拓扑同步

#### 3.1.1 获取节点列表
新增节点列表请求消息：

```python
def request_peer_list(self_id):
    """请求完整的节点列表"""
    from outbox import enqueue_message
    
    # 选择几个已知节点作为种子节点
    seed_peers = list(known_peers.items())[:3]  # 最多选择3个
    
    msg = {
        "type": "GET_PEERS",
        "sender_id": self_id,
        "message_id": generate_message_id()
    }
    
    for peer_id, (peer_ip, peer_port) in seed_peers:
        enqueue_message(peer_id, peer_ip, peer_port, msg)
```

处理节点列表请求：

```python
def handle_get_peers(msg, self_id):
    """处理GET_PEERS请求，返回已知节点列表"""
    sender_id = msg.get("sender_id")
    
    if sender_id not in known_peers:
        return  # 未知节点，忽略请求
    
    sender_ip, sender_port = known_peers[sender_id]
    
    # 准备节点列表响应
    peers_data = {}
    for peer_id, (ip, port) in known_peers.items():
        if peer_id != sender_id and peer_id != self_id:
            peers_data[peer_id] = {
                "ip": ip,
                "port": port,
                "flags": peer_flags.get(peer_id, {})
            }
    
    response = {
        "type": "PEERS_LIST",
        "sender_id": self_id,
        "peers": peers_data,
        "message_id": generate_message_id()
    }
    
    # 发送响应
    from outbox import enqueue_message
    enqueue_message(sender_id, sender_ip, sender_port, response)
```

处理节点列表响应：

```python
def handle_peers_list(msg, self_id):
    """处理PEERS_LIST响应，更新已知节点"""
    peers_data = msg.get("peers", {})
    
    new_peers = []
    
    for peer_id, info in peers_data.items():
        if peer_id != self_id and peer_id not in known_peers:
            ip = info.get("ip")
            port = info.get("port")
            flags = info.get("flags", {})
            
            # 添加到已知节点
            known_peers[peer_id] = (ip, port)
            peer_flags[peer_id] = flags
            new_peers.append(peer_id)
    
    return new_peers
```

#### 3.1.2 心跳机制维护
保持现有的PING/PONG机制，确保新节点的活跃状态得到维护。

### 3.2 区块链数据同步

#### 3.2.1 初始区块请求
优化区块同步过程，为新节点提供快速同步：

```python
def request_block_sync(self_id, is_new_node=False):
    """请求区块同步，新节点有特殊处理"""
    from block_handler import get_latest_block_height
    from outbox import enqueue_message
    
    current_height = get_latest_block_height()
    
    # 选择几个稳定节点作为同步源
    sync_sources = []
    for peer_id, (ip, port) in known_peers.items():
        if peer_id != self_id and peer_status.get(peer_id) == 'ALIVE':
            sync_sources.append((peer_id, ip, port))
            if len(sync_sources) >= 3:
                break
    
    if is_new_node and current_height == 0:
        # 新节点的初始同步 - 分批请求区块
        batch_size = 100  # 每批请求的区块数
        
        for source_id, source_ip, source_port in sync_sources:
            msg = {
                "type": "GET_BLOCK_HEADERS",
                "sender_id": self_id,
                "start_height": 0,
                "end_height": batch_size - 1,
                "message_id": generate_message_id()
            }
            enqueue_message(source_id, source_ip, source_port, msg)
    else:
        # 常规同步 - 请求最新区块
        for source_id, source_ip, source_port in sync_sources:
            msg = {
                "type": "GET_LATEST_BLOCK",
                "sender_id": self_id,
                "current_height": current_height,
                "message_id": generate_message_id()
            }
            enqueue_message(source_id, source_ip, source_port, msg)
```

## 4. 节点退出网络的过程

### 4.1 优雅退出

#### 4.1.1 退出通知
实现GOODBYE消息：

```python
def send_goodbye_message(self_id, reason="normal_shutdown"):
    """发送优雅退出通知，并转发未确认交易"""
    from outbox import enqueue_message
    from transaction import get_recent_transactions
    
    # 获取本地交易池中的交易
    pending_txs = get_recent_transactions()
    
    msg = {
        "type": "GOODBYE",
        "sender_id": self_id,
        "reason": reason,
        "pending_transactions": pending_txs if len(pending_txs) <= 100 else [],  # 限制大小
        "has_more_transactions": len(pending_txs) > 100,  # 指示是否有更多交易
        "message_id": generate_message_id(),
        "timestamp": time.time()
    }
    
    # 向所有已知节点广播退出消息
    for peer_id, (peer_ip, peer_port) in known_peers.items():
        if peer_id != self_id:
            enqueue_message(peer_id, peer_ip, peer_port, msg)
    
    # 如果交易太多，无法在GOODBYE消息中包含，则额外发送MEMPOOL_TRANSFER消息
    if len(pending_txs) > 100:
        # 将交易分批发送
        batch_size = 100
        active_peers = [peer_id for peer_id, status in peer_status.items() 
                       if status == 'ALIVE' and peer_id != self_id]
        
        if not active_peers:
            logger.warning("没有活跃节点可接收交易池转移")
            return
            
        # 随机选择一些活跃节点
        import random
        selected_peers = random.sample(active_peers, min(3, len(active_peers)))
        
        for i in range(0, len(pending_txs), batch_size):
            batch = pending_txs[i:i+batch_size]
            transfer_msg = {
                "type": "MEMPOOL_TRANSFER",
                "sender_id": self_id,
                "transactions": batch,
                "batch": i // batch_size + 1,
                "total_batches": (len(pending_txs) + batch_size - 1) // batch_size,
                "message_id": generate_message_id()
            }
            
            # 发送给选定的节点
            for peer_id in selected_peers:
                if peer_id in known_peers:
                    peer_ip, peer_port = known_peers[peer_id]
                    enqueue_message(peer_id, peer_ip, peer_port, transfer_msg)
                    
        logger.info(f"交易池转移：向 {len(selected_peers)} 个节点发送 {len(pending_txs)} 条交易")
    
    # 等待消息发送完成
    time.sleep(2)
    
    print(f"[{self_id}] Gracefully exiting the network", flush=True)
```

#### 4.1.2 资源清理
```python
def cleanup_resources(self_id):
    """清理节点资源"""
    # 完成挂起的交易
    # 保存区块链状态
    # 关闭连接
    
    print(f"[{self_id}] Resources cleaned up", flush=True)
```

### 4.2 网络更新

#### 4.2.1 节点信息移除
处理GOODBYE消息：

```python
def handle_goodbye_message(msg):
    """处理节点退出消息，包括接收转移的交易"""
    sender_id = msg.get("sender_id")
    reason = msg.get("reason", "unknown")
    pending_transactions = msg.get("pending_transactions", [])
    has_more_transactions = msg.get("has_more_transactions", False)
    
    if sender_id in known_peers:
        print(f"Peer {sender_id} is leaving the network. Reason: {reason}", flush=True)
        
        # 处理附带的交易
        if pending_transactions:
            from transaction import TransactionMessage, add_transaction
            added_count = 0
            
            for tx_data in pending_transactions:
                try:
                    tx = TransactionMessage.from_dict(tx_data)
                    add_transaction(tx)
                    added_count += 1
                except Exception as e:
                    logger.error(f"处理离开节点的交易时出错: {e}")
                    
            logger.info(f"从离开的节点 {sender_id} 接收 {len(pending_transactions)} 条交易，成功添加 {added_count} 条")
            
            if has_more_transactions:
                logger.info(f"节点 {sender_id} 还有更多交易将通过MEMPOOL_TRANSFER消息发送")
        
        # 从已知节点中移除
        if sender_id in known_peers:
            del known_peers[sender_id]
        
        # 移除其他相关信息
        if sender_id in peer_flags:
            del peer_flags[sender_id]
        
        if sender_id in peer_status:
            del peer_status[sender_id]
        
        if sender_id in reachable_by:
            del reachable_by[sender_id]
        
        # 更新配置
        update_dynamic_config()
```

## 5. 实现步骤

### 5.1 修改现有文件

1. **peer_discovery.py**
   - 增加对HELLO消息的扩展处理
   - 添加NEW_PEER消息类型及处理
   - 实现GET_PEERS/PEERS_LIST消息

2. **peer_manager.py**
   - 增强节点监控逻辑
   - 添加节点退出处理
   - 实现GOODBYE消息处理

3. **node.py**
   - 添加动态配置支持
   - 优化启动流程，处理新节点特殊情况
   - 添加优雅退出功能

4. **docker-compose.yml**
   - 修改现有配置以支持动态节点参数
   - 为所有节点添加`--dynamic`参数，启用动态发现功能

5. **config.json**
   - 保留现有的11个节点配置作为引导节点
   - 添加`dynamic_discovery: true`启用动态发现功能

6. **message_handler.py**
   - 新增消息类型处理
   - 添加对NEW_PEER, GOODBYE, MEMPOOL_TRANSFER等消息的支持

### 5.2 新增文件

1. **dynamic_node_manager.py**
   - 实现节点创建和管理功能
   - 提供Docker容器管理功能
   - 维护动态节点配置

## 6. Docker配置与使用

### 6.1 修改docker-compose.yml

为所有现有节点添加动态节点支持：

```yaml
version: '3'

services:
  peer5000:
    build: .
    volumes:
      - .:/app
    networks:
      blockchain_network:
        ipv4_address: 172.28.0.10
    ports:
      - "6000:5000"
      - "8000:7000"
    command: python node.py --id 5000 --config config.json --dynamic

  # 其他节点配置类似，添加 --dynamic 参数
```

### 6.2 创建新节点命令

**Linux/macOS环境**:
```bash
docker-compose run -d --name peer5011 --hostname peer5011 --ip 172.28.0.21 -p 6011:5011 -p 8011:7011 peer5000 python node.py --id 5011 --config config.json --dynamic
```

**Windows环境**:
```bash
docker-compose run -d --name peer5011 -p 6011:5011 -p 8011:7011 peer5000 python node.py --id 5011 --config config.json --dynamic
```

### 6.3 常见问题

1. **端口冲突**：创建新节点时可能出现"Address already in use"错误，表明端口已被占用。解决方法是更改端口映射或停止使用该端口的容器。

2. **网络问题**：Windows环境下可能出现"network starter_code_new not found"错误。解决方法是使用`docker network ls`查看正确的网络名称，通常是"starter_code_new_default"。

3. **导入错误**：节点启动后可能出现"cannot import name 'compute_tx_hash' from 'transaction'"错误。这表示`transaction.py`中缺少`compute_tx_hash`函数。需要在transaction.py中添加此函数或修改依赖它的代码。

## 7. 测试计划

1. **单节点测试**
   - 测试单个节点的创建和加入
   - 验证配置是否正确加载

2. **多节点动态测试**
   - 测试多个节点的同时加入
   - 验证节点间的发现和通信

3. **节点退出测试**
   - 测试节点的优雅退出
   - 测试节点的意外退出

4. **性能测试**
   - 测试大量节点加入/退出时的系统性能
   - 验证区块链数据同步效率

## 8. 附录：消息类型说明

本系统实现了以下新消息类型：

1. **NEW_PEER**: 通知现有节点有新节点加入网络
2. **GOODBYE**: 节点优雅退出网络时发送
3. **GET_PEERS/PEERS_LIST**: 获取和提供当前网络中的节点列表
4. **MEMPOOL_TRANSFER**: 传输交易池中的交易到其他节点
5. **GET_MEMPOOL/MEMPOOL_DATA**: 请求和提供交易池数据

## 9. 已知问题与限制

1. **Windows Docker兼容性**：Windows版Docker不支持某些Linux特有的网络选项，如`--hostname`和`--ip`标志，需要使用简化命令。

2. **导入错误**：部分节点可能出现导入错误，如"cannot import name 'compute_tx_hash' from 'transaction'"，需要确保代码库一致性。

3. **端口映射**：在Docker环境中创建多个节点时需要小心管理端口映射，避免冲突。

4. **网络发现延迟**：新节点加入网络后，可能需要一定时间才能被所有现有节点发现。

5. **交易同步**：在节点数量较多时，交易同步可能受到网络延迟影响。

## 10. 实际部署指南

### 10.1 Windows环境中的动态节点部署

我们的实际实现中，基于Windows环境，已成功实现动态节点的创建和管理。以下是实际部署过程中的经验：

1. **启动基础网络**
   - 首先启动docker-compose.yml中定义的11个基础节点(5000-5010)
   - 确保在所有节点的命令中添加`--dynamic`参数

2. **创建新节点**
   - 使用以下命令创建新节点：
   ```bash
   docker run -d --name peer5022 --network starter_code_new_default -p 6022:5022 -p 8022:7022 starter_code_new-peer5000:latest python node.py --id 5022 --config config.json --dynamic
   ```
   - 注意网络名称应该使用`docker network ls`查看到的正确名称

3. **检查节点连接**
   - 通过Docker Dashboard查看容器日志，确认节点之间的通信
   - 主要关注HELLO消息和NEW_PEER消息的交换

4. **处理可能的错误**
   - 端口冲突：每次创建新节点时使用不同的端口映射
   - 网络问题：确保所有节点连接到同一Docker网络
   - 导入错误：修改transaction.py添加缺失的compute_tx_hash函数

### 10.2 动态节点的实际效果

我们在测试中观察到以下效果：

1. **动态发现**：新节点加入后，通过HELLO消息被现有节点识别
2. **信息传播**：网络中的广播消息能够正确传递到新加入的节点
3. **区块同步**：新节点能够从现有节点同步区块链数据
4. **交易处理**：新节点能够处理和转发交易
